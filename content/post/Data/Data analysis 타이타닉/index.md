+++
author = "Hugo Authors"
title = "Data analysis íƒ€ì´íƒ€ë‹‰"
date = "2021-07-09"
description = "ë°ì´í„° ë¶„ì„ íŠœí† ë¦¬ì–¼ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ë¥  ì˜ˆì¸¡"
categories = [
    "Data"
]
tags = [
    "data analysis", "ë°ì´í„°ë¶„ì„", "tutorial", "titanic",

]

image = "titanic.jpg"

+++

# íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë¶„ì„ ğŸš¢

> ë³¸ê²©ì ìœ¼ë¡œ ë°ì´í„°ë¶„ì„ì— ë“œëŸ¬ê°€ê¸°ì— ì•ì„œ íŠœí† ë¦¬ì–¼ì„ ì§„í–‰í•´ë³´ë ¤í•œë‹¤.
>
> ì½”ë”©ì„ ì²˜ìŒ ë°°ìš¸ë•Œ `Hello World`ë¥¼ ì¶œë ¥í•˜ëŠ” ê²ƒ ì²˜ëŸ¼ ë°ì´í„°ë¶„ì„ì˜ ì‹œì‘ì€ `íƒ€ì´íƒ€ë‹‰ ë°ì´í„°`ì´ë‹¤!!

## Kaggleê³¼ Colab ì—°ë™

Google Colab í™˜ê²½ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆëŠ”ë° Kaggleì˜ data setì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í•˜ë‚˜í•˜ë‚˜ ë‹¤ìš´ë°›ì„ í•„ìš”ì—†ì´ APIë¥¼ ì´ìš©í•´ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

```python
# kaggleê³¼ colab ì—°ë™
!pip install kaggle

# kaggleì—ì„œ api kaggle.jsonì„ ë°›ì•„ì„œ ì „ì†¡
from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# APIë¡œ data set download
!kaggle competitions download -c 2019-1st-ml-month-with-kakr

# ì••ì¶•í•´ì œ
!unzip -q /content/2019-1st-ml-month-with-kakr
```

## ì™œ í•˜í•„ì´ë©´ íƒ€ì´íƒ€ë‹‰??

ë°ì´í„° ë¶„ì„ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ë¹ ë¥´ê²Œ ê²½í—˜í•  ìˆ˜ ìˆìœ¼ë©°, ì ‘ê·¼í•˜ê¸° ì¢‹ì€ Binary Classification ë¬¸ì œì´ê¸° ë•Œë¬¸ì—

## ì§„í–‰ í”„ë¡œì„¸ìŠ¤

1. ë°ì´í„°ì…‹ í™•ì¸

- ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì „ì²˜ë¦¬

2. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)

- ì—¬ëŸ¬ íŠ¹ì„±ë“¤ì„ ë¶„ì„í•˜ê³  ìƒê´€ê´€ê³„ë¥¼ í™•ì¸
- ì‹œê°í™”ë¥¼ í†µí•´ insight ë„ì¶œ

3. íŠ¹ì„±ê³µí•™(Feature Engineering)

- ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ íŠ¹ì„±ì„ ì—”ì§€ë‹ˆì–´ë§

4. ëª¨ë¸ ê°œë°œ ë° í•™ìŠµ

- sklearn, keras ë“±ì„ ì´ìš©í•´ ëª¨ë¸ì„ ì œì‘

5. ëª¨ë¸ ì˜ˆì¸¡ ë° í‰ê°€

- í›ˆë ¨ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ì˜ˆì¸¡í•©ë‹ˆë‹¤.

  ---

## 1. ë°ì´í„°ì…‹ í™•ì¸

```python
# ë°ì´í„°ì…‹ í™•ì¸
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import keras
import sklearn

# seaborn ì…‹íŒ… => matplotlibì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ìƒ‰ìƒ í…Œë§ˆì™€ í†µê³„ìš© ê¸°ëŠ¥ì„ ì¶”ê°€í•œ ì‹œê°í™” íŒ¨í‚¤ì§€
plt.style.use('seaborn')
sns.set(font_scale=2.5)

import missingno as msno

import warnings
# ê²½ê³  ë©”ì‹œì§€ ìƒëµ
warnings.filterwarnings('ignore')

%matplotlib inline
```

```python
df_train = pd.read_csv('train.csv')
df_test = pd.read_csv('test.csv')
df_submit = pd.read_csv('sample_submission.csv')
```

```python
df_train.head()
```

![](train_head.PNG)

### ë°ì´í„° Feature ì„¤ëª…

- survival - ìƒì¡´ìœ ë¬´ => target ê°’ (0=ì‚¬ë§, 1=ìƒì¡´)
- pclass - í‹°ì¼“í´ë˜ìŠ¤
- sex - ì„±ë³„
- age - ë‚˜ì´
- sibsp - í•¨ê»˜ íƒ‘ìŠ¹í•œ í˜•ì œìë§¤, ë°°ìš°ì ìˆ˜ ì´í•©
- parch - í•¨êº¼ íƒ‘ìŠ¹í•œ ë¶€ëª¨, ìë…€ ìˆ˜ ì´í•©
- ticket - í‹°ì¼“ ë„˜ë²„
- fare - íƒ‘ìŠ¹ ìš”ê¸ˆ
- cabin - ê°ì‹¤ ë„˜ë²„
- bembarked - íƒ‘ìŠ¹ í•­êµ¬

```python
# ê²°ì¸¡ì¹˜ í™•ì¸ => train setê³¼ test setì— ë¹„ìŠ·í•˜ê²Œ ageì— 20% cabinì— 80%ì˜ ê²°ì¸¡ì§€ ë°œê²¬
df_train.isnull().sum() / df_train.shape[0]
```

![](train_nan.png)

### Target Label í™•ì¸

target labelì´ ì–´ë–¤ distributionì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸ í•„ìš”
binary classificationì—ì„œ ë¶„í¬ê°€ ì–´ë– ëƒì— ë”°ë¼ ëª¨ë¸ì˜ í‰ê°€ë°©ë²•ì´ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì—

```python
f, ax = plt.subplots(1, 2, figsize=(18, 8))

# íŒŒì´ê·¸ë˜í”„
df_train['Survived'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)
ax[0].set_title('Pie plot - Survived')
ax[0].set_ylabel('')
# í•­ëª©ë³„ ê°œìˆ˜ë¥¼ ì¹´ìš´íŠ¸
sns.countplot('Survived', data=df_train, ax=ax[1])
ax[1].set_title('Count plot - Survived')

plt.show()
# target labelì˜ ë¶„í¬ê°€ ì œë²• ê· ì¼í•˜ë¯€ë¡œ binary classificationì— ì í•©
```

![](pie.png)

### íŒŒì´ê·¸ë˜í”„ ì†ì„±

>plt.pie(slice, labels=activities, startangle=90, shadow=True, explode=(0, 0, 0.1, 0), autopct='%1.1f%%')

- slice: íŒŒì´ ì¡°ê°ì˜ ë°ì´í„°

- labels: íŒŒì´ ì¡°ê°ì˜ ë¼ë²¨

- startangle: ê·¸ë ¤ì§€ëŠ” íŒŒì´ ì¡°ê° ì‹œì‘ ìœ„ì¹˜

- shadow: íŒŒì´ ì°¨íŠ¸ì˜ ê·¸ë¦¼ì íš¨ê³¼ ìœ ë¬´

- explode: íŒŒì´ ì¡°ê°ì´ ëŒì¶œë˜ëŠ” í¬ê¸°

- autopct: íŒŒì´ ì¡°ê°ì˜ ì „ì²´ ëŒ€ë¹„ ë°±ë¶„ìœ¨

  ---

## 2. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(Exploratory Data Analysys)

Featureë³„ë¡œ ë°ì´í„° ë¶„ì„ Insight ë„ì¶œí•´ë³´ì

### 1. Pclass

- PclassëŠ” ì„œìˆ˜í˜• ë°ì´í„°ì…ë‹ˆë‹¤.
- Pclass,Survived ë¥¼ ê°€ì ¸ì˜¨ í›„, pclass ë¡œ ë¬¶ìœ¼ë©´ ê° pclass ë§ˆë‹¤ 0, 1 ì´ countê°€ ë˜ëŠ”ë°, ì´ë¥¼ í‰ê· ë‚´ë©´ ê° pclass ë³„ ìƒì¡´ë¥ ì´ ì¶”ì¶œ

```python
# ìƒì¡´ë¥ 
df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).mean()
```

![](ìƒì¡´ë¥ .png)

```python
# ë§‰ëŒ€ê·¸ë˜í”„ ì‹œê°í™”
df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).mean().plot.bar()
# ìƒì¡´ë¥ ì— Pclassê°€ í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.
# ë”°ë¼ì„œ ëª¨ë¸ ìƒì„±ì‹œ í•´ë‹¹ feature ì‚¬ìš©ì´ ì¢‹ì„ ê²ƒì´ë¼ íŒë‹¨
```

![](ë§‰ëŒ€ê·¸ë˜í”„.png)

### 2. Sex

```python
f, ax = plt.subplots(1, 2, figsize=(18, 8))
df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=True).mean().plot.bar(ax=ax[0])
ax[0].set_title('Survived vs Sex')
sns.countplot('Sex', hue='Survived', data=df_train, ax=ax[1])
ax[1].set_title('Sex: Survived vs Dead')
plt.show()
# ë‚¨ì„±ë³´ë‹¤ ì—¬ì„±ì˜ ìƒì¡´í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.
# Pclassì™€ ë§ˆì°¬ê°€ì§€ë¡œ, Sexë„ ì˜ˆì¸¡ ëª¨ë¸ì— ì“°ì¼ ì¤‘ìš” featuredì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.
```

![](ì„±ë³„.png)

### 3. Both Sex and Pclass

```python
# factorí˜•ì˜ ë³€ìˆ˜ì˜ ì‹œê°í™”ë¥¼ í•  ë•Œ ìœ ìš©í•œ ì‹œê°í™”
sns.factorplot('Pclass', 'Survived', hue='Sex', data=df_train, size=6, aspect=1.5)
# ëª¨ë“  í´ë˜ìŠ¤ì—ì„œ ì—¬ì„±ì˜ ìƒì¡´ë¥ ì´ ë‚¨ì„±ë³´ë‹¤ ë†’ë‹¤.
```

![](factor.png)

### 4. Age

```python
# ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ì–´ë–¤ ë¶„í¬ë¡œ í¼ì ¸ìˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ì—†ë‹¤. ê·¸ë˜ì„œ ë¶„í¬ë¥¼ í™•ì¸í•  ë•ŒëŠ” íˆìŠ¤í† ê·¸ë¨ì„ ì‚¬ìš©
# but, íˆìŠ¤í† ê·¸ë¨ì€ êµ¬ê°„ì„ ì–´ë–»ê²Œ ì„¤ì •í•˜ëƒì— ë”°ë¼ ê²°ê³¼ë¬¼ì´ í¬ê²Œ ë‹¬ë¼ì§„ë‹¤.
# ê·¸ ëŒ€ì•ˆìœ¼ë¡œ ë¶„í¬ë¥¼ ê³¡ì„ í™” ì‹œì¼œì£¼ëŠ” ì»¤ë„ë°€ë„ì¶”ì •(KDE)ì„ ë§ì´ ì‚¬ìš©
fig, ax = plt.subplots(1, 1, figsize=(9, 5))
sns.kdeplot(df_train[df_train['Survived'] == 1]['Age'], ax=ax)
sns.kdeplot(df_train[df_train['Survived'] == 0]['Age'], ax=ax)
plt.legend(['Survived == 1', 'Survived == 0'])
plt.show()
# ìƒì¡´ KDEì™€ ì‚¬ë§ KDEë¥¼ ë¹„êµí–ˆì„ë•Œ ì–´ë¦°ë‚˜ì´ êµ¬ê°„ì—ì„œ ìƒì¡´ë¥ ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.
```

![](kde.png)

```python
cummulate_survival_ratio = []
for i in range(1, 80):
    cummulate_survival_ratio.append(df_train[df_train['Age'] < i]['Survived'].sum() / len(df_train[df_train['Age'] < i]['Survived']))
    
plt.figure(figsize=(7, 7))
plt.plot(cummulate_survival_ratio)
plt.title('Survival rate change depending on range of Age', y=1.02)
plt.ylabel('Survival rate')
plt.xlabel('Range of Age(0~x)')
plt.show()
# ë‚˜ì´ê°€ ì–´ë¦´ìˆ˜ë¡ ìƒì¡´ë¥ ì´ í™•ì‹¤íˆ ì¦ê°€í•˜ëŠ” ê²ƒì„ í™•ì¸ ê°€ëŠ¥
# Ageë„ ì¤‘ìš” featureì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```

![](age.png)

### 5. Embarked

```python
f, ax = plt.subplots(1, 1, figsize=(7, 7))
df_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax)
# íƒ‘ìŠ¹í•­êµ¬ ë³„ ìƒì¡´ë¥ ì˜ ì°¨ì´ê°€ í¬ì§„ ì•Šë‹¤.
```

![](emb.png)

```python
# ë‹¤ë¥¸ featureì™€ì˜ ìƒê´€ê´€ê³„
f,ax=plt.subplots(2, 2, figsize=(20,15))
sns.countplot('Embarked', data=df_train, ax=ax[0,0])
ax[0,0].set_title('(1) No. Of Passengers Boarded')
sns.countplot('Embarked', hue='Sex', data=df_train, ax=ax[0,1])
ax[0,1].set_title('(2) Male-Female Split for Embarked')
sns.countplot('Embarked', hue='Survived', data=df_train, ax=ax[1,0])
ax[1,0].set_title('(3) Embarked vs Survived')
sns.countplot('Embarked', hue='Pclass', data=df_train, ax=ax[1,1])
ax[1,1].set_title('(4) Embarked vs Pclass')
plt.subplots_adjust(wspace=0.2, hspace=0.5)
plt.show()
```

![](emb2.png)

* Figure(1) - ì „ì²´ì ìœ¼ë¡œ ë´¤ì„ ë•Œ, S ì—ì„œ ê°€ì¥ ë§ì€ ì‚¬ëŒì´ íƒ‘ìŠ¹í–ˆìŠµë‹ˆë‹¤.
* Figure(2) - Cì™€ Q ëŠ” ë‚¨ë…€ì˜ ë¹„ìœ¨ì´ ë¹„ìŠ·í•˜ê³ , SëŠ” ë‚¨ìê°€ ë” ë§ìŠµë‹ˆë‹¤.
* Figure(3) - ìƒì¡´í™•ë¥ ì´ S ê²½ìš° ë§ì´ ë‚®ì€ ê±¸ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì´ì „ ê·¸ë˜í”„ì—ì„œ ë´¤ì—ˆìŠµë‹ˆë‹¤)
* Figure(4) - Class ë¡œ split í•´ì„œ ë³´ë‹ˆ, Cê°€ ìƒì¡´í™•ë¥ ì´ ë†’ì€ê±´ í´ë˜ìŠ¤ê°€ ë†’ì€ ì‚¬ëŒì´ ë§ì´ íƒ€ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤. SëŠ” 3rd class ê°€ ë§ì•„ì„œ ìƒì¡´í™•ë¥ ì´ ë‚®ê²Œ ë‚˜ì˜µë‹ˆë‹¤.

### 6. Family(Sibsp + Parch)

```python
# Sibspì™€ Parchë¥¼ í•©ì¹˜ë©´ í•¨ê»˜ íƒ‘ìŠ¹í•œ ê°€ì¡±ì˜ ìˆ˜ê°€ ë˜ë¯€ë¡œ ìƒˆë¡œìš´ Feature ìƒì„±
df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 # ìì‹ ì„ í¬í•¨í•´ì•¼í•˜ë‹ˆ 1ì„ ë”í•©ë‹ˆë‹¤
df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 # ìì‹ ì„ í¬í•¨í•´ì•¼í•˜ë‹ˆ 1ì„ ë”í•©ë‹ˆë‹¤
```

```python
f,ax=plt.subplots(1, 3, figsize=(40,10))
sns.countplot('FamilySize', data=df_train, ax=ax[0])
ax[0].set_title('(1) No. Of Passengers Boarded', y=1.02)

sns.countplot('FamilySize', hue='Survived', data=df_train, ax=ax[1])
ax[1].set_title('(2) Survived countplot depending on FamilySize',  y=1.02)

df_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax[2])
ax[2].set_title('(3) Survived rate depending on FamilySize',  y=1.02)

plt.subplots_adjust(wspace=0.2, hspace=0.5)
plt.show()
```

![](family.png)

* Figure (1) - ê°€ì¡±í¬ê¸°ê°€ 1~11ê¹Œì§€ ìˆìŒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ 1ëª…ì´ê³  ê·¸ ë‹¤ìŒìœ¼ë¡œ 2, 3, 4ëª…ì…ë‹ˆë‹¤.
* Figure (2), (3) - ê°€ì¡± í¬ê¸°ì— ë”°ë¥¸ ìƒì¡´ë¹„êµì…ë‹ˆë‹¤. ê°€ì¡±ì´ 4ëª…ì¸ ê²½ìš°ê°€ ê°€ì¥ ìƒì¡´í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤,
ê°€ì¡±ìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡, (5, 6, 7, 8, 11) ìƒì¡´í™•ë¥ ì´ ë‚®ì•„ì§€ë„¤ìš”.
ê°€ì¡±ìˆ˜ê°€ ë„ˆë¬´ ì‘ì•„ë„(1), ë„ˆë¬´ ì»¤ë„(5, 6, 8, 11) ìƒì¡´ í™•ë¥ ì´ ì‘ë„¤ìš”. 3~4ëª… ì„ ì—ì„œ ìƒì¡´í™•ë¥ ì´ ë†’ì€ ê±¸ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 7. Fare

```python
# íƒ‘ìŠ¹ìš”ê¸ˆì€ ì—°ì†ì ì¸ ë°ì´í„°ì´ë¯€ë¡œ íˆìŠ¤í† ê·¸ë¨ ì‹œê°í™”
fig, ax = plt.subplots(1, 1, figsize=(8, 8))
g = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)
g = g.legend(loc='best')
```

```python
# íŠ¹ì´í•˜ê¸°ë„ train set ë§ê³  test setì— Fare í”¼ì³ì— ë„ ê°’ì´ í•˜ë‚˜ ì¡´ì¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
# ê·¸ë˜ì„œ í‰ê·  ê°’ìœ¼ë¡œ í•´ë‹¹ ë„ê°’ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
df_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean() # testset ì— ìˆëŠ” nan value ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
# logë¥¼ ì·¨í•´ ë³´ê¸° í¸í•˜ê²Œ ë³€í™˜
df_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)
df_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)

fig, ax = plt.subplots(1, 1, figsize=(8, 8))
g = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)
g = g.legend(loc='best')
```

![](fare.png)

### 8. Cabin

NaNì´ ëŒ€ëµ 80% ì´ë¯€ë¡œ, ìƒì¡´ì— ì˜í–¥ì„ ë¯¸ì¹  ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì–»ì–´ë‚´ê¸°ê°€ ì‰½ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.

### 9. Ticket

NaNì€ ì—†ì§€ë§Œ ì´ ë°ì´í„°ë¡œ ìœ íš¨í•œ ê²°ê³¼ë¥¼ ë½‘ì•„ë‚´ê¸°ìœ„í•´ì„  ì•„ì´ë””ì–´ê°€ í•„ìš”

---

## 3. íŠ¹ì„±ê³µí•™(Feature Engineering)

### Fill Null

null dataë¥¼ ì–´ë–»ê²Œ ì±„ìš°ëŠëƒì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢Œì§€ìš°ì§€ë˜ë¯€ë¡œ ì¤‘ìš”, train ë¿ë§Œ ì•„ë‹ˆë¼ testë„ ë˜‘ê°™ì´ ì ìš©

#### 1. Age

```python
df_train['Initial']= df_train.Name.str.extract('([A-Za-z]+)\.') #lets extract the Salutations
df_test['Initial']= df_test.Name.str.extract('([A-Za-z]+)\.') #lets extract the Salutations
```

```python
# Initialê³¼ Sexê°„ì˜ count
pd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap='summer_r') #Checking the Initials with the Sex
```

```python
df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],
                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)

df_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],
                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)
```

```python
# train ì—ì„œ ì–»ì€ statistics ë¥¼ ê¸°ë°˜ìœ¼ë¡œ null data ì±„ìš°ê¸°
df_train.groupby('Initial').mean()
```

```python
# ê° initial ê·¸ë£¹ë³„ Age í‰ê·  ê°’ì„ ì‚¬ìš©í•´ì„œ ì±„ìš°ê¸°
df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mr'),'Age'] = 33
df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mrs'),'Age'] = 36
df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Master'),'Age'] = 5
df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Miss'),'Age'] = 22
df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Other'),'Age'] = 46

df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mr'),'Age'] = 33
df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mrs'),'Age'] = 36
df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Master'),'Age'] = 5
df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Miss'),'Age'] = 22
df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Other'),'Age'] = 46
```

#### 2. Embarked

```python
# Sì—ì„œ ê°€ì¥ ë§ì´ íƒ”ìœ¼ë¯€ë¡œ Së¡œ ì±„ìš°ê¸°
df_train['Embarked'].fillna('S', inplace=True)
df_train.isnull().sum()[df_train.isnull().sum() > 0]
```

### Change Age

AgeëŠ” continuous featureì´ì§€ë§Œ ê·¸ë£¹í™”í•˜ì—¬ ì¹´í…Œì½”ë¦¬í™” ì‹œì¼œì¤„ ìˆ˜ ìˆë‹¤.
continousë¥¼ categoricalë¡œ ë°”ê¾¸ë©´ impormation lossê°€ ìƒê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜

```python
def category_age(x):
    if x < 10:
        return 0
    elif x < 20:
        return 1
    elif x < 30:
        return 2
    elif x < 40:
        return 3
    elif x < 50:
        return 4
    elif x < 60:
        return 5
    elif x < 70:
        return 6
    else:
        return 7    
    
df_train['Age_cat'] = df_train['Age'].apply(category_age)
df_test['Age_cat'] = df_test['Age'].apply(category_age)
```

![](group.png)

### Change Initial, Embarked and Sex

ì»´í“¨í„°ê°€ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì¹˜í™”

```python
df_train['Initial'] = df_train['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})
df_test['Initial'] = df_test['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})

df_train['Embarked'] = df_train['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})
df_test['Embarked'] = df_test['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})

df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})
df_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1})
```

```python
# ê° featureë³„ ìƒê´€ê´€ê³„ ì‹œê°í™”
heatmap_data = df_train[['Survived', 'Pclass', 'Sex', 'Fare', 'Embarked', 'FamilySize', 'Initial', 'Age_cat', 'Age']] 

colormap = plt.cm.RdBu
plt.figure(figsize=(14, 12))
plt.title('Pearson Correlation of Features', y=1.05, size=15)
sns.heatmap(heatmap_data.astype(float).corr(), linewidths=0.1, vmax=1.0,
           square=True, cmap=colormap, linecolor='white', annot=True, annot_kws={"size": 16})

del heatmap_data
```

![](heat.png)

* Sex ì™€ Pclass ê°€ Survived ì— ìƒê´€ê´€ê³„ê°€ ì–´ëŠ ì •ë„ ìˆìŒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ìƒê°ë³´ë‹¤ fare ì™€ Embarked ë„ ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ” featureë“¤ì´ ì—†ë‹¤.
ë”°ë¼ì„œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œ, ë¶ˆí•„ìš”í•œ feature ê°€ ì—†ë‹¤.

### ë°ì´í„°ì „ì²˜ë¦¬(Data Preprocessing)

ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •

#### One-hot encoding on Initiall and Embarked
One-hot encodingì„ í†µí•´ ê° í´ë˜ìŠ¤ê°„ ì—°ê´€ì„±ì„ ë™ì´í•˜ê²Œ ìƒì„±<br>
categoryê°€ ë§ì„ ê²½ìš° columnì´ ë„ˆë¬´ ë§ì´ ìƒì„±ë˜ì–´ `ì°¨ì›ì˜ ì €ì£¼` ë°œìƒ ì£¼ì˜

```python
df_train = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')
df_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')
```

![](one_hot.png)

```python
df_train = pd.get_dummies(df_train, columns=['Embarked'], prefix='Embarked')
df_test = pd.get_dummies(df_test, columns=['Embarked'], prefix='Embarked')
```

#### Drop Columns

í•„ìš”ì—†ëŠ” í”¼ì³ ì œê±°

```python
df_train.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)
df_test.drop(['PassengerId', 'Name',  'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)
```

## 4. ëª¨ë¸ ê°œë°œ ë° í•™ìŠµ

Sklearnì€ ë¨¸ì‹ ëŸ¬ë‹ì— ê´€ë ¨ëœ ëª¨ë“  ì‘ì—…ë“¤ì´ ì†ì‰¬ìš´ ì¸í„°í˜ì´ìŠ¤ë¡œ êµ¬í˜„ë˜ì–´ ìˆë‹¤.
í˜„ì¬ ìš°ë¦¬ëŠ” train setì˜ survivedë¥¼ ì œì™¸í•œ inputì„ ê°€ì§€ê³  ëª¨ë¸ì„ ìµœì í™” ì‹œì¼œ íƒ‘ìŠ¹ê°ì˜ ìƒì¡´ìœ ë¬´ë¥¼ íŒë‹¨í•˜ëŠ” ëª¨ë¸ì„ ìƒì„±
ê·¸ í›„ test setì„ inputìœ¼ë¡œ ì£¼ì–´ì„œ íƒ‘ìŠ¹ê°ì˜ ìƒì¡´ìœ ë¬´ë¥¼ ì˜ˆì¸¡

```python
#importing all the required ML packages
from sklearn.ensemble import RandomForestClassifier # ìœ ëª…í•œ randomforestclassfier ì…ë‹ˆë‹¤. 
from sklearn import metrics # ëª¨ë¸ì˜ í‰ê°€ë¥¼ ìœ„í•´ì„œ ì”ë‹ˆë‹¤
from sklearn.model_selection import train_test_split # traning setì„ ì‰½ê²Œ ë‚˜ëˆ ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

### Preparation - Split dataset into train, valid, test set

â€‹```python
X_train = df_train.drop('Survived', axis=1).values
target_label = df_train['Survived'].values
X_test = df_test.values
```

```python
X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.2, random_state=2018)
```

### Model generation and prediction

#### Random Forest

ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ ì¤‘ ëœë¤í¬ë ˆìŠ¤íŠ¸ë¥¼ ì‚¬ìš©
ëœë¤í¬ë ˆìŠ¤íŠ¸ëŠ” ê²°ì •íŠ¸ë¦¬ê¸°ë°˜ ëª¨ë¸ë¡œ ì—¬ëŸ¬ ê²°ì • íŠ¸ë¦¬ë“¤ì„ ì•™ìƒë¸”í•œ ëª¨ë¸

```python
model = RandomForestClassifier() # ìƒì„±
model.fit(X_tr, y_tr) # í•™ìŠµ
prediction = model.predict(X_vld) # ì˜ˆì¸¡
```

```python
print('ì´ {}ëª… ì¤‘ {:.2f}% ì •í™•ë„ë¡œ ìƒì¡´ì„ ë§ì¶¤'.format(y_vld.shape[0], 100 * metrics.accuracy_score(prediction, y_vld)))
# ì´ 179ëª… ì¤‘ 81.56% ì •í™•ë„ë¡œ ìƒì¡´ì„ ë§ì¶¤
```

```python
# í•™ìŠµëœ ëª¨ë¸ì€ feature importanceë¥¼ ê°€ì§€ê²Œ ë˜ëŠ”ë°,
# ì´ëŠ” ì–´ë–¤ featureê°€ ê²°ê³¼ì— ì˜í–¥ì„ ë§ì´ ë¯¸ì³¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
from pandas import Series

feature_importance = model.feature_importances_
Series_feat_imp = Series(feature_importance, index=df_test.columns)
```

```python
plt.figure(figsize=(8, 8))
Series_feat_imp.sort_values(ascending=True).plot.barh()
plt.xlabel('Feature importance')
plt.ylabel('Feature')
plt.show()
```

![](importance.png)

#### NNëª¨ë¸(Neural Network model) - ë”¥ëŸ¬ë‹ ëª¨ë¸

```python
from keras.models import Sequential
from keras.layers.core import Dense, Dropout
from keras.optimizers import Adam, SGD

nn_model = Sequential()
nn_model.add(Dense(32,activation='relu',input_shape=(14,)))
nn_model.add(Dropout(0.2))
nn_model.add(Dense(64,activation='relu'))
nn_model.add(Dropout(0.2))
nn_model.add(Dense(32,activation='relu'))
nn_model.add(Dropout(0.2))
nn_model.add(Dense(1,activation='sigmoid'))

Loss = 'binary_crossentropy'
nn_model.compile(loss=Loss,optimizer=Adam(),metrics=['accuracy'])
```

```python
history = nn_model.fit(X_tr,y_tr, batch_size=64, epochs=500, validation_data=(X_vld, y_vld), verbose=1)
```

```python
hists = [history]
hist_df = pd.concat([pd.DataFrame(hist.history) for hist in hists], sort=True)
hist_df.index = np.arange(1, len(hist_df)+1)
fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))
axs[0].plot(hist_df.val_accuracy, lw=5, label='Validation Accuracy')
axs[0].plot(hist_df.accuracy, lw=5, label='Training Accuracy')
axs[0].set_ylabel('Accuracy')
axs[0].set_xlabel('Epoch')
axs[0].grid()
axs[0].legend(loc=0)
axs[1].plot(hist_df.val_loss, lw=5, label='Validation MLogLoss')
axs[1].plot(hist_df.loss, lw=5, label='Training MLogLoss')
axs[1].set_ylabel('MLogLoss')
axs[1].set_xlabel('Epoch')
axs[1].grid()
axs[1].legend(loc=0)
fig.savefig('hist.png', dpi=300)
plt.show();
```

![](nn_model.png)

## 5. ëª¨ë¸ ì˜ˆì¸¡ ë° í‰ê°€

### ëœë¤í¬ë ˆìŠ¤íŠ¸

```python
submission = pd.read_csv('sample_submission.csv')
prediction = model.predict(X_test)
submission['Survived'] = prediction
submission.to_csv('my_first_submission.csv', index=False)
# ì •í™•ë„ ìŠ¤ì½”ì–´: 0.75598
```

### NNëª¨ë¸

```python
submission = pd.read_csv('sample_submission.csv')
prediction = nn_model.predict(X_test)
prediction = prediction > 0.5
prediction = prediction.astype(np.int)
prediction = prediction.T[0]
submission['Survived'] = prediction
submission.to_csv('my_nn_submission.csv', index=False)
# ì •í™•ë„ ì‚¬ì½”ì–´: 0.77990
```

---

`Google Colab`í™˜ê²½ì—ì„œ ì§„í–‰í•˜ê³  `markdown`ìœ¼ë¡œ í¬ìŠ¤íŒ…í•˜ëŠ” ê±°ë¼ ì„¤ëª…ì´ ë¶€ì¡±í•œ ì ì€ ì–‘í•´ë°”ëë‹ˆë‹¤;;ğŸ’¦ğŸ’¦

ì˜ˆì „ì— ì ê¹ í•´ë³´ì•˜ë˜ ë°ì´í„°ë¶„ì„ì´ì§€ë§Œ ì˜¤ëœë§Œì— ë‹¤ì‹œí•œë²ˆ í•´ë³´ë‹ˆ ê°íšŒê°€ ìƒˆë¡œì› ê³  ì§„í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ëŠë‚€ ê¶ê¸ˆì ë“¤ì€ ë”°ë¡œ ì •ë¦¬í•˜ì—¬ í¬ìŠ¤íŒ…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¹!!!

ì›ë³¸ì†ŒìŠ¤ì½”ë“œ.ipynb ğŸ‘‰ https://github.com/ssabum/note/blob/master/data_analysis/titanic.ipynb

